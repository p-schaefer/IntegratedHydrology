---
title: "ihydro: Integrated hydrology tools for environmental science"
always_allow_html: true
output: 
  github_document:
    toc: true
    pandoc_args: --webtex
editor_options: 
  markdown: 
    wrap: 72
  chunk_output_type: console
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```



## 1.0 Introduction

```{r pressure, echo=FALSE, out.width = '75%', fig.align = 'center'}
knitr::include_graphics("man/figures/README-unnamed-chunk-6-1.png")
```

Aquatic environmental scientists are often tasked with relating landscape factors to observed responses in streams, rivers and lakes. The computational workflow for conducting these investigations is complex. Simply describing how water flows and accumulates across the landscape can be a challenge itself, but for aquatic scientists it is only the first step. The stream network must then be extracted from the landscape, and reaches (a.k.a. segments; i.e., stretches of river between two confluences) identified and given unique identifiers. These reaches must then be attributed to be informative (e.g., slope, stream order, upstream channel length, etc.); and upstream-downstream connectivity between reaches established.

Typically, sampling data is available at points along the stream network. If the specific information about the location of these points is to be preserved (i.e., if samples are upstream and downstream of a particular effluent outflow, but along the same stream reach), they must be incorporated into the network. Once that is done, factors of interest on the landscape (e.g., landcover, soils, geology, climate, etc.) must be related to the reach (or sampling points). This alone can be complex as the spatial configuration of these factors relative to flow direction and accumulation are important. The ***ihydro*** package uses the ***hydroweight*** package to calculate these attributes.

The complexity of this workflow can be a rate limiting step in the scope, content, quality, and applicability of aquatic environmental scientist investigations. The ***ihydro*** package offers tools and workflows to simplify these complex steps. It is capable of handling all above computation steps, leaving researchers the task of identifying layers of interest and modeling with (potentially) large numbers of predictors.

The ***ihydro*** package also implements a novel form of describing spatial autocorrelation among sites. Due to the linear nature of flow in streams and rivers, autocorrelation tends to be asymmetric, with downstream sites potentially more similar to upstream sites when they are flow connected, than not flow connected (regardless of spatial proximity). ***ihydro*** produces an asymmetric matrix that describes the relationships between sampling points based on the proportions of an upstream catchment that is shared with a target site. Proportion of shared upstream catchment (rather than in-stream distance) is a more relevant measure of spatial autocorrelation in streams because it accounts for differences in catchment areas between points. For example, if water chemistry samples are taken from a large 6th order stream, and a upstream small 1st order tributary we would expect the small tributary to have only a small impact on the larger stream. Hence autocorrelation should be low because the tributary is not contributing much flow to the large stream. If using in-stream distances, the assumed autocorrelation may be high because the physical distance is small, but this would be incorrect.

***ihydro*** stores its geospatial products in a \code{*.zip} file for easy of retrieval and plotting in external software. It can be run in parallel for increased speed (if enough memory is available), and is quick at removing internal intermediate files to keep hard drives from filling up too fast.

[Back to top](#Introduction)

## 2.0 System setup and installation

*WhiteboxTools* and *whitebox* are required for ***ihydro***. See
[whiteboxR](https://github.com/giswqs/whiteboxR) or below for
installation.

```{r, eval = FALSE}
## Follow instructions for whitebox installation accordingly
## devtools::install_github("giswqs/whiteboxR") # For development version
## whitebox is now available on CRAN
#install.packages("whitebox")

library(whitebox)

if (F){
  install_whitebox()
  # Possible warning message:
  # ------------------------------------------------------------------------
  # Could not find WhiteboxTools!
  # ------------------------------------------------------------------------
  #
  # Your next step is to download and install the WhiteboxTools binary:
  #     > whitebox::install_whitebox()
  #
  # If you have WhiteboxTools installed already run `wbt_init(exe_path=...)`':
  #    > wbt_init(exe_path='/home/user/path/to/whitebox_tools')
  #
  # For whitebox package documentation, ask for help:
  #    > ??whitebox
  #
  # For more information visit https://giswqs.github.io/whiteboxR/
  #
  # ------------------------------------------------------------------------
}

```

[Back to top](#Introduction)

## 3.0 Prepare DEM and Sampling Points for for analysis

### 3.1 Generate toy terrain dataset and sampling points

Begin by bringing in the digital elevation model and using it to generate terrain products. The DEM must be processed in a way to remove depressions. Whitebox offers methods for breaching and filling DEMs to remove depressions. These tools must be run before applying ihydro tools. 

Another factor to consider at this step is whether to burn stream vectors into the DEM;  \code{whitebox::wbt_fillburn()} tool allows for this, but  there are several caveats associated with this process. See [here](https://proceedings.esri.com/library/userconf/proc99/proceed/papers/pap802/p802.htm#Trois)


```{r, message = FALSE, error = FALSE, warning = FALSE}
## Load libraries
library(viridis)
library(ihydro)
library(mapview)
library(furrr)
library(whitebox)
library(terra)
library(sf)
library(dplyr)

# Many function in 'ihydro' can be run in parallel internally. However itâ€™s important to remember that
# data has to be passed back and forth between the workers. This means that whatever performance gain you might have
# gotten from your parallelization can be crushed by moving large amounts of data around. In general, passing objects
# as file paths will be faster than passing whole sf or terra objects. Not returning products directly will also speed
# up function processing time dramatically. Products can always be retrieved/read in directly from the output .zip
# file.
if (F) plan(multisession)

## Generate save_dir as a temporary directory
save_dir <- tempdir()


## Import toy_dem from openSTARS package
# devtools::install_github("MiKatt/openSTARS", ref = "dev")

system.file("extdata", "nc", "elev_ned_30m.tif", package = "openSTARS") %>% 
  rast() %>% 
  set.crs(crs(rast(system.file("extdata", "nc", "landuse_r.tif", package = "openSTARS")))) %>% 
  writeRaster(file.path(save_dir, "toy_dem1.tif"),overwrite=T)

toy_dem<-rast(file.path(save_dir, "toy_dem1.tif"))


# Bring in and process stream vector
system.file("extdata", "nc", "streams.shp", package = "openSTARS") %>% 
  vect() %>% 
  st_as_sf() %>% 
  st_transform(st_crs(toy_dem)) %>% 
  vect() %>% 
  writeVector(file.path(save_dir, "toy_streams.shp"),overwrite=T)

burn_lyr<-vect(file.path(save_dir, "toy_streams.shp")) %>% 
  rasterize(toy_dem)

# rudimentary stream burning
burn_lyr2<-toy_dem
burn_lyr2[is.na(burn_lyr)]<-NA 
burn_lyr2<-burn_lyr2-5
toy_dem[!is.na(burn_lyr2)]<-burn_lyr2[!is.na(burn_lyr2)]

writeRaster(toy_dem,file.path(save_dir, "toy_dem.tif"),overwrite=T)

## Breach depressions to ensure continuous flow
wbt_breach_depressions(
  dem = file.path(save_dir, "toy_dem.tif"),
  output = file.path(save_dir, "toy_dem_breached.tif")
)

toy_dem<-rast(file.path(save_dir, "toy_dem_breached.tif"))

## Identify some sampling points
system.file("extdata", "nc", "sites_nc.shp", package = "openSTARS") %>% 
  vect() %>% 
  st_as_sf() %>% 
  st_transform(st_crs(toy_dem)) %>% 
  vect() %>% 
  writeVector(file.path(save_dir, "sites.shp"),overwrite=T)

plot(toy_dem)

```


[Back to top](#Introduction)

### 3.2 Generate predictor layers


```{r, fig.width = 7, fig.height = 7, message = FALSE, error = FALSE, warning = FALSE}

## Predictors from openSTARS
system.file("extdata", "nc", "landuse_r.tif", package = "openSTARS") %>% 
  rast() %>% 
  setNames("LC") %>% 
  writeRaster(file.path(save_dir, "LC.tif"),overwrite=T)

landuse_r_path <-file.path(save_dir, "LC.tif") 
geology_path<-system.file("extdata", "nc", "geology.shp", package = "openSTARS")
pointsources_path<-system.file("extdata", "nc", "pointsources.shp", package = "openSTARS")

read_sf(pointsources_path) %>% 
  mutate(pointsource="pontsrc") %>% 
  st_buffer(60) %>% 
  write_sf(file.path(save_dir, "pointsources.shp"),overwrite=T)

pointsources_path<-file.path(save_dir, "pointsources.shp")


# Numeric Raster

wbt_slope(
  dem = file.path(save_dir, "toy_dem.tif"),
  output = file.path(save_dir, "slope.tif")
)

# Combine loi layers
output_filename_loi<-file.path(save_dir,"Processed_loi.zip")

# This function sequentially combines numeric and categorical loi layers,
# it can be run with at most 2 processes (1 numeric and 1 categorical).
# Most operations occur out of memory, but the sequential nature means 
# temporary files won't eat valuable hardrive space.
plan(multisession(workers=2))

loi_combined<-process_loi(
  dem=toy_dem,
  num_inputs=list(# Can be given as a mixture of input types (file paths, or any sf or terra format)
    slope=file.path(save_dir, "slope.tif")
  ),
  cat_inputs=list(# Can be given as a mixture of input types (file paths, or any sf or terra format)
    landcover=landuse_r_path,
    geology=geology_path,
    pointsources=pointsources_path
  ),
  variable_names=list( # any unlisted inputs will be used in their entirety
    geology="GEO_NAME",
    pointsources="pontsrc"
  ),
  output_filename=output_filename_loi,
  return_products=T,
  temp_dir=NULL,
  verbose=T
)

# All layers have been transformed to rasters with 1 indicating presence, and NA for absence
plot(rast(loi_combined$cat_inputs),type="classes",col="darkgreen")

```

```{r, fig.width = 7, fig.height = 7, message = FALSE, error = FALSE, warning = FALSE}
# Numeric Rasters
plot(rast(loi_combined$num_inputs),type="continuous")

```

[Back to top](#Introduction)

## 4.0 Generate geospatial analysis products

### 4.1 METHOD 1: Individually

#### 4.1.1 Generate flow direction/accumulation geospatial analysis products with `process_flowdir()`

```{r, fig.width = 7, fig.height = 7, message = FALSE, error = FALSE, warning = FALSE}

# Outputs of all functions are always saved to output_filename by default,
# but can be included in function return with return_products=T (note this can
# be very slow for large regions)
output_filename_hydro<-file.path(save_dir,"Processed_Hydrology.zip")

# Generates d8 flow direction and accumulation, extracts streams at a specified 
# flow accumulation threshold
hydro_out<-process_flowdir(
  dem=toy_dem,
  threshold=100L,  
  return_products=T,
  output_filename=output_filename_hydro,
  temp_dir=NULL, 
  verbose=F
)

# hydro_out$outfile # -> This is the full file path of the resulting .zip file

# remaining outputs only present when `return_products` == T
# hydro_out$dem_final.tif # -> dem
# hydro_out$dem_d8.tif # -> d8 flow direction
# hydro_out$dem_accum_d8.tif # -> d8 flow accumulation (cells)
# hydro_out$dem_accum_d8_sca.tif # -> d8 flow accumulation (specific catchment areas)
# hydro_out$dem_streams_d8.tif # -> extracted streams at specified `threshold`

# if `return_products` == F, all produces are also available in the .zip file
# terra and sf allow access to files directly in the .zip file, whitebox
# requires them to be extracted to a folder

# List files present in .zip
fl<-unzip(list=T, # when list==T, contents are listed only, if F, they are extracted
          hydro_out$outfile)

flow_accum_path<-file.path("/vsizip", # "/vsizip" allows terra and sf functions to read from .zip files
                           hydro_out$outfile, # Then specify the full path to the zip file
                           fl$Name[grepl("dem_accum_d8.tif",fl$Name)] # finally specify the file to extract
)

# > flow_accum_path
# [1] "/vsizip/C:\\Users\\PSCHAE~1\\AppData\\Local\\Temp\\RtmpMnq0AY\\Processed_Hydrology.zip/dem_accum_d8.tif"

flow_accum<-rast(flow_accum_path)

plot(log10(flow_accum))

```

[Back to top](#Introduction)

#### 4.1.2 Generate vector geospatial analysis products with `generate_vectors()`

This function combines `generate_subbasins()` and `attrib_streamline()` to produce a number of vector layers.

```{r, fig.width = 7, fig.height = 7, message = FALSE, error = FALSE, warning = FALSE}

plan(multisession) # improve processing time in some functions with parallel processing

# generates vector layers, including subbasins, stream lines, and links representing
# pour-points for each subbasin
hydro_out<-generate_vectors(
  input=hydro_out,
  return_products=T,
  temp_dir=NULL,
  verbose=F
) 

# Several important columns are used throughout the vector layers:
# `link_id` - identifies reaches/segments (steam between two confluences)
# `trib_id` - identifies streams/tributaries, with the shortest channel getting
#           # a new trib_id at a confluence, and longest channel retaining the original ID
# `uslink_id` and `dslink_id`  - columns identify upstream and downstream links
# `ustrib_id` and `dstrib_id`  - columns identify upstream and downstream tributaries

# New layers added by `generate_vectors()`
# hydro_out$subbasins # -> polygon subbasins attributed with `link_id` and reach
#                     #    contributing area (in m^2)
# hydro_out$stream_lines # -> line vectors attributed with `link_id`, `trib_id`, upstream
#                        #    and downstream link and trib IDS and a number of extra attributes
# hydro_out$points # -> point vectors along lines identifying 'nodes' (confluence
#                  #     points), vs 'links' segments joining 'nodes', and also
#                  #     attributed with `link_id`, `trib_id`, upstream
#                  #     and downstream link and trib IDS and a number of extra attributes
# hydro_out$links # -> point vector representing pour-points for subbasins,
#                 #   attributed with `link_id` and extra attributes

mapview(hydro_out$subbasins,zcol="link_id",legend=F,layer.name=".",alpha.regions=0.1)+
  mapview(hydro_out$stream_lines,legend=F,layer.name="..",lwd=2,alpha=1)+
  mapview(hydro_out$links,zcol="link_id",legend=F,layer.name="...",cex=2)
```

[Back to top](#Introduction)

#### 4.1.3 Split vector geospatial analysis products at sampling points `insert_points()`

Typically, sampling data is available at points along the stream network. If the specific information about the location of these points is to be preserved (i.e., if samples are upstream and downstream of a particular effluent outflow, but along the same stream reach), they must be incorporated into the network.

```{r, fig.width = 7, fig.height = 7, message = FALSE, error = FALSE, warning = FALSE}

# Optional step, inserts sampling points into stream vectors, splitting subbasins
# and lines at sampling points, additional links inserted at sampling points as well
hydro_out<-insert_points( 
  input=hydro_out,
  points=file.path(save_dir, "sites.shp"),
  site_id_col="site_id", # Column in points layer that corresponds to unique IDs that will be available in data products
  snap_distance=250L,
  return_products=T,
  temp_dir=NULL,
  verbose=F
)

# New layers added by `insert_points()`
# hydro_out$snapped_points # -> provided points snapped to nearest segment. Any points 
#                          #   beyond snap distance are removed, with a warning. 

# This function also modifies the existing vector outputs by inserting links, and 
# splitting lines/subbasins at `points`, and adds the `site_id_col` column to 
# all vector outputs. Inserted points are given "link_id' values that increment
# with decimal places from downstream to upstream directions (i.e., 10.0 remains
# the pout point for the segment, and 10.1, 10.2,... identify sample points in
# an upstream direction). 

mapview(hydro_out$subbasins,zcol="link_id",legend=F,layer.name=".",alpha.regions=0.1)+
  mapview(hydro_out$stream_lines,legend=F,layer.name="..",lwd=2,alpha=1)+
  mapview(hydro_out$snapped_points,zcol="site_id",legend=F,color="red",layer.name="....",cex=6)

```

[Back to top](#Introduction)

#### 4.1.4 Create lookup table of flow-directions with `trace_flowpaths()`

To more efficiently generate catchments, look-ups are created that identify the upstream and downstream links from each link. If `insert_points()` was run previously, inserted points are also included in lookups.


```{r, fig.width = 7, fig.height = 7, message = FALSE, error = FALSE, warning = FALSE}

# Creates lookup tables of upstream and downstream flow paths
hydro_out<-trace_flowpaths(
  input=hydro_out,
  return_products=T,
  temp_dir=NULL,
  verbose=F
)

# New layers added by `insert_points()`
# hydro_out$ds_flowpaths # -> named list of all link_ids, giving all downstream link_ids
#                        #    trib_ids, link lengths (in meters) and subbasin areas (in meters^2)
# hydro_out$us_flowpaths # -> named list of all link_ids, giving all upstream link_ids
#                        #    trib_ids, link lengths (in meters) and subbasin areas (in meters^2)

us_777<-hydro_out$us_flowpaths[["777"]] # get all upstream link_ids from link_id 777
ds_1107.1<-hydro_out$ds_flowpaths[["1107.1"]] # get all downstream link_ids from 
#                                             # link_id 1107.1 (this corresponds with site_id = 45)

lines_out<-hydro_out$stream_lines %>% 
  filter(link_id %in% us_777$link_id | 
           link_id %in% ds_1107.1$link_id 
  )
sub_out<-hydro_out$subbasins %>% 
  filter(link_id %in% us_777$link_id | 
           link_id %in% ds_1107.1$link_id
  )

mapview(sub_out,zcol="link_id",legend=F,layer.name=".",alpha.regions=0.3)+
  mapview(lines_out,legend=F,layer.name="..",lwd=2,alpha=1)

```

[Back to top](#Introduction)

#### 4.1.5 Generate complete upstream catchment areas with `get_catchment()`

```{r, fig.width = 7, fig.height = 7, message = FALSE, error = FALSE, warning = FALSE}

# Once lookup tables are calculated (not necessarily returned, can be return_products = F),
# catchments can easily be retrieved:

subbasin_catchments<-get_catchment( # retrieve catchment for an arbitrary reach
  input=hydro_out,
  site_id_col=NULL,
  target_points=c("838")
)

point_catchments<-get_catchment( # retrieve sampling point catchments
  input=hydro_out,
  site_id_col="site_id",
  target_points=c("1","25")
)

mapview(hydro_out$stream_lines,legend=F,layer.name="..",lwd=2,alpha=1)+
  mapview(point_catchments,zcol="link_id",legend=F, color = "black", lwd = 5,alpha.regions=0.8,layer.name="...")+
  mapview(subbasin_catchments,zcol="link_id",legend=F, color = "Yellow", lwd = 5,alpha.regions=0.8,layer.name="....")

```

[Back to top](#Introduction)

#### 4.1.6 Generate pairwise distances with `generate_pwisedist()`


```{r, fig.width = 7, fig.height = 7, message = FALSE, error = FALSE, warning = FALSE}

hydro_out<-generate_pwisedist(
  input=hydro_out,
  return_products=T,
  temp_dir=NULL,
  verbose=F
)

# New layers added by `generate_pwisedist()`
# hydro_out$pwise_dist$long_pwise # -> table of downstream path lengths between each pair of link_ids,
#                                 #    with in-stream distances (directed_path_length)
#                                 #    and proportions of shared catchments (prop_shared_catchment)
# hydro_out$pwise_dist$wide_prop_shared_catchment # -> wide table of prop_shared_catchment
# hydro_out$pwise_dist$wide_directed_path_length  # -> wide table of directed_path_length

# Examine relationships among sampled sites. 

# Get link_id for sampled points
sel_link_id<-hydro_out$snapped_points #%>% 
#filter(site_id != 25)

# filter long table to selected sites, and convert to wide format
dmat<-hydro_out$pwise_dist$long_pwise %>% 
  filter(origin %in% sel_link_id$link_id &
           destination %in% sel_link_id$link_id
  ) %>% 
  select(-prop_shared_catchment) %>%
  rename(link_id=origin) %>%
  select(-origin_catchment,-destination_catchment) %>%
  mutate(directed_path_length=ifelse(directed_path_length==1,0,directed_path_length)) %>% 
  pivot_wider(names_from=destination,values_from=directed_path_length ,values_fill = 0) %>% 
  data.frame(check.names = F) %>% 
  tibble::column_to_rownames("link_id") 

heatmap(as.matrix(dist(log1p(dmat)))) #log transformation used to adjust to normalize distances

```

```{r, fig.width = 7, fig.height = 7, message = FALSE, error = FALSE, warning = FALSE}

# Using path legths allows the identification of groups of spatially proximate
# site, these can be used for cross-validation groups
km<-kmeans(dist(log1p(dmat)),6)

gps<-tibble::enframe(km$cluster,"link_id","group") %>% 
  mutate(link_id=as.numeric(link_id))

point_groups<-hydro_out$snapped_points %>% 
  left_join(gps) %>% 
  filter(!is.na(group))

mapview(hydro_out$subbasins,zcol="link_id",legend=F,layer.name=".",alpha.regions=0.1)+
  mapview(hydro_out$stream_lines,legend=F,layer.name="..",lwd=2,alpha=1)+
  mapview(point_groups,zcol="group",legend=F,color="red",layer.name="....",cex=6)

```

[Back to top](#Introduction)

### 4.2 METHOD 2: With a single function

#### 4.2.1 `process_hydrology()`

```{r, fig.width = 7, fig.height = 7, message = FALSE, error = FALSE, warning = FALSE}

# The entire workflow above can be accomplished with a single function:

output_filename_hydro_sparse<-file.path(save_dir,"Processed_Hydrology_sparse.zip")

# In this case we won't provide the points, and use a higher initaition threshold.
# We will use this layer to more quickly make predictions across the landscape.

hydro_out_sparse<-process_hydrology(
  dem=toy_dem,
  output_filename=output_filename_hydro_sparse,
  threshold=1000L,
  points=NULL, # file.path(save_dir, "sites.shp"),
  pwise_dist=T,
  return_products=F,
  temp_dir=NULL,
  verbose=F
)

# unzip(list=T,hydro_out_sparse$outfile)

mapview(read_sf(file.path("/vsizip",hydro_out_sparse$outfile,"Subbasins_poly.shp")),
        zcol="link_id",legend=F,layer.name=".",alpha.regions=0.1)+
  mapview(read_sf(file.path("/vsizip",hydro_out_sparse$outfile,"stream_lines.shp")),
          legend=F,layer.name="..",lwd=2,alpha=1)+
  mapview(read_sf(file.path("/vsizip",hydro_out_sparse$outfile,"stream_links.shp")),zcol="link_id",
          legend=F,layer.name="...",cex=2)
```

[Back to top](#Introduction)

## 5.0 Add layers of interest to geospatial analysis products

### 5.1 `process_loi()`

```{r, fig.width = 7, fig.height = 7, message = FALSE, error = FALSE, warning = FALSE}

# Instead of processing loi separately (as was done above), they can also be
# added to the completed workflow, and added to the existing .zip file
# for convenient file storage/organization. If run separately (as above), 
# "num_rast.tif" and/or "cat_rast.tif" can manually be added to the .zip file as well.

# Here we will out our previously calculated loi results below

if (F) {
  plan(multisession(workers=2))
  hydro_out<-process_loi(
    input=hydro_out,
    num_inputs=list(# Can be given as a mixture of input types (file paths, or any sf or terra format)
      slope=file.path(save_dir, "slope.tif")
    ),
    cat_inputs=list(# Can be given as a mixture of input types (file paths, or any sf or terra format)
      landcover=landuse_r_path,
      geology=geology_path,
      pointsources=pointsources_path
    ),
    variable_names=list( # any unlisted inputs will be used in their entirety
      geology="GEO_NAME",
      pointsources="pontsrc"
    ),
    return_products=T, # these layers can get large, and it is generally not advised to return them into R 
    temp_dir=NULL,
    verbose=F
  )
}

```

[Back to top](#Introduction)

## 6.0 Calculate (weighted) spatial summaries
### 6.1 At sampleing points with site specific attributes `attrib_points()`

```{r, fig.width = 7, fig.height = 7, message = FALSE, error = FALSE, warning = FALSE}

# 

loi<-list(numb=rast(loi_combined$num_inputs),
          cat=rast(loi_combined$cat_inputs))

loi_names<-lapply(loi,names) %>% unlist()
names(loi_names)<-loi_names
loi_names<-map(loi_names,~c("distwtd_mean",  "mean", "distwtd_sd",  "min", "max"))

# A 'spec' table can be given to calculate attributes at only select sampling points,
# and/or to only calculate a subset of attributes from select sampling points
specification_table<-tibble(
  site_id=c("1","25","80"),
  loi=list(loi_names)
)
specification_table$loi[[2]]<-specification_table$loi[[2]][c(1:2)]
specification_table$loi[[2]][[1]]<-specification_table$loi[[2]][[1]][c(1:2)]

# specification_table$loi[[2]]
plan(multisession) # improve processing time in some functions with parallel processing

final_attributes_sub<-attrib_points(
  input=hydro_out,
  loi_file=output_filename_loi,
  spec=specification_table,
  weighting_scheme = c("lumped", "iFLO", "iFLS", "HAiFLO", "HAiFLS"),
  OS_combine=F,
  target_streamseg=F, # This will set the target_o parameter as the sampling point
  inv_function = function(x) {
    (x * 0.001 + 1)^-1
  },
  remove_region=NULL,
  return_products=T,
  temp_dir=NULL,
  verbose=F
)

# Site 25 should only contain mean and distwtd_mean variables for ruggedness
final_attributes_sub %>% 
  select(site_id,contains("ruggedness"))

```

```{r, fig.width = 7, fig.height = 7, message = FALSE, error = FALSE, warning = FALSE}

# We can also access the weighting layers and weighted attribute layers (if return_products==T)
plot(rast(
  list(rast(final_attributes_sub$distance_weights[[2]]$iFLS.tif)%>% 
         setNames("iFLS Weighting"),
       log10(rast(final_attributes_sub$distance_weights[[2]]$HAiFLS.tif))%>% 
         setNames("HAiFLS Weighting"),
       rast(final_attributes_sub$weighted_attr[[2]]$num_rast.distwtd_meandistwtd_sdmaxmeanmin.iFLS_num_rast.loi_dist_rast) %>% 
         project(rast(final_attributes_sub$distance_weights[[2]]$HAiFLS.tif)) %>% 
         setNames("iFLS Weighted Slope"),
       rast(final_attributes_sub$weighted_attr[[2]]$cat_rast.mean.iFLS_cat_rast.loi_dist_rast)[[9]] %>% 
         project(rast(final_attributes_sub$distance_weights[[2]]$HAiFLS.tif)) %>% 
         setNames("HAiFLS Weighted Landcover Class 1")
  )
))

```

[Back to top](#Introduction)

### 6.2 At sampleing points `attrib_points()`

```{r, fig.width = 7, fig.height = 7, message = FALSE, error = FALSE, warning = FALSE}

loi_names<-lapply(loi,names) %>% unlist()
names(loi_names)<-loi_names
loi_names<-map(loi_names,~c("distwtd_mean"))

# Here we will calculate the attributes for all sampled points
specification_table<-tibble(
  site_id=hydro_out$snapped_points$site_id,
  loi=list(loi_names)
)

# specification_table$loi[[2]]
plan(multisession(workers=4)) # improve processing time in some functions with parallel processing

final_attributes_samples<-attrib_points(
  input=hydro_out,
  loi_file=output_filename_loi,
  spec=specification_table,
  weighting_scheme = c("HAiFLO", "HAiFLS"),
  OS_combine=F,
  target_streamseg=F, # This will set the target_o parameter as the sampling point
  inv_function = function(x) {
    (x * 0.001 + 1)^-1
  },
  remove_region=NULL,
  return_products=F,
  temp_dir=NULL,
  verbose=F
)

```

[Back to top](#Introduction)

### 6.3 Across entire study area `attrib_points()`

```{r error=FALSE, fig.height=7, fig.width=7, message=FALSE, warning=FALSE}

plan(multisession(workers=4)) # improve processing time in some functions with parallel processing

# Warning this operation can be very slow - but we will use our sparse
# hydrology network
final_attributes_all<-attrib_points(
  input=hydro_out_sparse,
  all_reaches=T, # This will calculate attributes for each reach
  weighting_scheme = c("HAiFLO", "HAiFLS"),
  loi_numeric_stats = c("distwtd_mean"),
  OS_combine=F,
  target_streamseg=T # This will set the target_o parameter as the entire reach
)

final_attributes_all

```

[Back to top](#Introduction)
